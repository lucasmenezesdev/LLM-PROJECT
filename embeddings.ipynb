{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\lucas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucas\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm\n",
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "file_path = 'drive/MyDrive/datasets/PLN/Dados-abertos-COFOG-GC-2022.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin1', delimiter=';')\n",
    "\n",
    "# Função de pooling para obter embeddings\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# Inicializar o modelo e tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to('cuda')\n",
    "\n",
    "# Função para gerar embeddings para uma coluna em lotes\n",
    "def get_embeddings(texts, batch_size=1024):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Gerando embeddings\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_dict = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        embeddings.append(F.normalize(batch_embeddings, p=2, dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Diretório para salvar os embeddings\n",
    "output_dir = 'output_embeddings'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Gerar e salvar embeddings para cada coluna\n",
    "embeddings_dict = {}\n",
    "for column in tqdm(data.columns, desc=\"Processando colunas\"):\n",
    "    texts = data[column].astype(str).tolist()\n",
    "    embeddings = get_embeddings(texts)\n",
    "    embeddings_dict[column] = embeddings\n",
    "    np.save(os.path.join(output_dir, f'{column}_embeddings.npy'), embeddings)\n",
    "\n",
    "print(\"Embeddings gerados e salvos com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Armazenando embeddings para NATUREZA DESPESA DETALHADA DESCRICAO:   0%|          | 0/75991 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Inicializar o cliente ChromaDB\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Função para limpar e validar nomes de coleções\n",
    "def clean_column_name(name):\n",
    "    clean_name = name.strip().replace(' ', '_').replace('.', '_').replace('-', '_')\n",
    "    clean_name = ''.join(c for c in clean_name if c.isalnum() or c in ['_', '-'])\n",
    "    return clean_name[:63]\n",
    "\n",
    "# Função para verificar se uma coleção já existe\n",
    "def collection_exists(client, name):\n",
    "    try:\n",
    "        client.get_collection(name=name)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Diretório onde os embeddings estão salvos\n",
    "output_dir = 'drive/MyDrive/datasets/PLN/output_embeddings/'\n",
    "\n",
    "# Colunas que você quer carregar e testar\n",
    "columns_to_test = ['NATUREZA DESPESA DETALHADA DESCRICAO', 'ACAO GOVERNO DESCRICAO']\n",
    "\n",
    "# Carregar embeddings de arquivos .npy para ChromaDB\n",
    "collections = {}\n",
    "embeddings_dict = {}\n",
    "\n",
    "try:\n",
    "    for column in columns_to_test:\n",
    "        clean_name = clean_column_name(column)\n",
    "        file_path = os.path.join(output_dir, f\"{clean_name}_embeddings.npy\")\n",
    "\n",
    "        # Carregar os embeddings do arquivo .npy\n",
    "        embeddings = np.load(file_path)\n",
    "        embeddings_dict[clean_name] = embeddings\n",
    "\n",
    "        # Certifique-se de que a coleção existe, caso contrário, crie-a\n",
    "        if not collection_exists(client, clean_name):\n",
    "            collection = client.create_collection(name=clean_name)\n",
    "        else:\n",
    "            collection = client.get_collection(name=clean_name)\n",
    "\n",
    "        # Armazenar embeddings no ChromaDB\n",
    "        for i, embedding in enumerate(tqdm(embeddings, desc=f\"Armazenando embeddings para {column}\")):\n",
    "            try:\n",
    "                collection.add(ids=[f\"{clean_name}_{i}\"], embeddings=[embedding.tolist()], metadatas=[{\"index\": i}])\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao adicionar embedding {i} para {column}: {e}\")\n",
    "\n",
    "        collections[clean_name] = collection\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar a similaridade usando um dos embeddings carregados\n",
    "query_vector = embeddings_dict['NATUREZA_DESPESA_DETALHADA_DESCRICAO'][0]\n",
    "results = collections['NATUREZA_DESPESA_DETALHADA_DESCRICAO'].query(vector=query_vector.tolist(), top_k=5)\n",
    "\n",
    "for result in results['ids']:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
